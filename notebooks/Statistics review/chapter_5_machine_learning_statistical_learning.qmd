
---
title: "Chapter 5: Machine Learning and Statistical Learning"
format: 
  pdf:
    toc: true
    number-sections: true
    number-depth: 2
    fig-cap-location: bottom
    fig-align: center
    keep-tex: true
    link-citations: true
    reference-location: document
    citecolor: blue
---

# 5. Machine Learning and Statistical Learning (Mathematical Foundations)

This chapter introduces the theory behind machine learning (ML) from a statistical learning perspective.

## 5.1 Supervised Learning Framework

Given $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$, find $f$ minimizing expected loss:

$$
f^*(x) = \arg\min_f \ \mathbb{E}_{X,Y} [ L(Y, f(X)) ]
$$

Empirical risk minimization:

$$
\hat{f} = \arg\min_f \ \frac{1}{n} \sum_{i=1}^n L(y_i, f(x_i))
$$

## 5.2 Common Algorithms

### Decision Trees

Minimize impurity:

$$
\sum_{m=1}^M \sum_{i \in R_m} (y_i - \bar{y}_{R_m})^2
$$

### Random Forest

Ensemble of bootstrapped trees:

$$
\hat{f}(x) = \frac{1}{B} \sum_{b=1}^B T_b(x)
$$

### Gradient Boosting

Additive model:

$$
\hat{f}_m(x) = \hat{f}_{m-1}(x) + \nu \cdot h_m(x)
$$

Minimizes:

$$
\sum_{i=1}^n L(y_i, \hat{f}_m(x_i)) + \Omega(h_m)
$$

## 5.3 Support Vector Machines (SVMs)

### Linear SVM

$$
\min_{w, b} \ \frac{1}{2} \|w\|^2 \quad \text{s.t. } y_i(w^\top x_i + b) \geq 1
$$

### Soft Margin

$$
\min_{w, b, \xi} \ \frac{1}{2} \|w\|^2 + C \sum \xi_i \quad \text{s.t. } y_i(w^\top x_i + b) \geq 1 - \xi_i
$$

## 5.4 K-Nearest Neighbors (KNN)

Predict based on $k$ closest points:

- Regression: average of $y_i$
- Classification: majority vote

## 5.5 Naive Bayes

Assume conditional independence:

$$
P(y \mid x) \propto P(y) \cdot \prod_{j=1}^p P(x_j \mid y)
$$

## 5.6 Unsupervised Learning

### K-Means

Minimize within-cluster sum of squares:

$$
\min_{\{C_k\}} \sum_k \sum_{x_i \in C_k} \|x_i - \mu_k\|^2
$$

### PCA

Project onto directions maximizing variance:

- Eigenvectors of $\Sigma = \frac{1}{n} X^\top X$

## 5.7 Model Selection and Validation

- Train/test split
- K-fold CV
- Grid/Random search

### Metrics

- **Classification**: Accuracy, Precision, Recall, F1, AUC
- **Regression**: MSE, MAE, RMSE
